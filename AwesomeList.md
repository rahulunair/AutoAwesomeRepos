# Awesome GitHub Repos

A curated list of awesome oneAPI GitHub repositories related to various categories.

## Table of Contents

### Tools & Development

- [optimum-intel](https://github.com/huggingface/optimum-intel):keyword: intel_neural_compressor:  license: Unknown License: The Optimum Intel library is a toolkit that enables high performance inference capabilities for Intel CPUs, GPUs and special DL inference accelerators. It is supplied with a set of tools to optimize your models with compression techniques such as quantization, pruning and knowledge distillation. The Optimum Intel library provides a simple interface to optimize your transformers and diffusers models, convert them to the OpenVINO intermediate representation (IR) format and run inference using OpenVINO runtime ![GitHub stars](https://img.shields.io/badge/stars-122-blue)
- [neural-compressor](https://github.com/intel/neural-compressor):keyword: intel_neural_compressor:  license: Unknown License: Intel Neural Compressor is an open source Python library that supports popular model compression techniques on all mainstream deep learning frameworks, including TensorFlow, PyTorch, ONNX Runtime, and MXNet. The tool also showcases key features, typical examples, and broad collaborations with other software platforms and open AI ecosystems ![GitHub stars](https://img.shields.io/badge/stars-1005-blue)
- [optimum](https://github.com/huggingface/optimum):keyword: intel_neural_compressor:  license: Unknown License: The text describes the various features of the Optimum library for training and running machine learning models on different hardware platforms. Optimum provides support for popular compression techniques, such as quantization and pruning, and also enables accelerated training on various hardware accelerators. Examples are given for how to use Optimum to train and run inference on models hosted on different platforms ![GitHub stars](https://img.shields.io/badge/stars-1005-blue)

### AI - Computer Vision

- [models](https://github.com/onnx/models):keyword: intel_neural_compressor:  license: Unknown License: The text describes the onnx model zoo, a collection of pre-trained machine learning models in the onnx format. The model zoo includes models for image classification, object detection, and other tasks. Each model includes accompanying jupyter notebooks for training and running inference. The onnx model zoo is supported by a community of partners who have implemented it in many frameworks and tools ![GitHub stars](https://img.shields.io/badge/stars-5665-blue)

### AI - Natural Language Processing

- [intel-extension-for-transformers](https://github.com/intel/intel-extension-for-transformers):keyword: intel_neural_compressor:  license: Unknown License: The Intel Extension for Transformers is a toolkit that accelerates transformer-based models on Intel platforms. It provides features such as model compression, optimization, and quantization, and comes with examples and tutorials. It is effective on 4th Intel Xeon Scalable Processor Sapphire Rapids ![GitHub stars](https://img.shields.io/badge/stars-145-blue)

